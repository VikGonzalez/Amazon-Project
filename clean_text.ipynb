{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of unpleasant words to check\n",
    "unpleasant = ['lousy','disappointed','discouraged','ashamed','powerless','diminished','guilty','dissatisfied',\n",
    "        'miserable','detestable','repugnant','despicable','disgusting','abominable','terrible','in despair',\n",
    "        'sulky','bad','upset','doubtful','uncertain','indecisive','perplexed','embarassed','hesitant',\n",
    "        'shy','stupefied','disillusioned','unbelieving','skeptical','distrustful','misgiving','lost',\n",
    "        'unsure','uneasy','pessimistic','tense''incapable','alone','paralyzed','fatigued','useless',\n",
    "        'inferior','vulnerable','empty','forced','hesitant','despair','frustrated','distressed','woeful',\n",
    "        'pathetic','tragic','in a stew','dominated','irritated','enraged','hostile','insulting',\n",
    "        'annoyed','upset','hateful','offensive','bitter','aggresive','resentful','inflamed','provoked',\n",
    "        'incensed','infuriated','cross','worked up','boiling','fuming','fearful','terrified','suspicious',\n",
    "        'anxious','alarmed','panic','nervous','scared','worried','frightened','timid','shaky','restless',\n",
    "        'doubtful','threatened','cowardly','quaking','wary','crushed','tormented','deprived','pained',\n",
    "        'tortured','dejected','rejected','injured','offended','afflicted','aching','victimized',\n",
    "        'heartbroken','agonized','appalled','humiliated','wronged','alienated','tearful','sorrowful',\n",
    "        'pained','grief','anguish','desolate','desperate','pessimistic','unhappy','lonely','grieved',\n",
    "        'mournful','dismayed','insensitive','dull','nonchalant','neutral','reserved','weary','bored',\n",
    "        'preoccupied','cold','disinterested','lifeless', 'never'];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of pleasant words to check\n",
    "pleasant = ['understanding','confident','reliable','easy','amazed','free','sympathetic','interested','satisfied',\n",
    "            'receptive','accepting','kind', 'great','joyous','lucky','fortunate','delighted','overjoyed','gleeful','thankful','important',\n",
    "            'festive','ecstatic','glad','cheerful','elated','jubilant', 'playful','courageous','energetic','liberated','optimistic',\n",
    "            'impulsive','free','animated','spirited','thrilled','wonderful','calm','peaceful','at ease','comfortable','pleased','encouraged',\n",
    "            'clever','surprised','content','quiet','certain','relaxed','serene','reassured', 'loving','considerate','affectionate', 'sensitive',\n",
    "            'tender','devoted','attracted','passionate','admiration','warm','touched','close','comforted','loved','concerned','affected','fascinated',\n",
    "            'intrigued','absorbed','inquisitive','engrossed','curious','drawn toward','eager','keen','earnest','intent','inspired','determined','excited',\n",
    "            'enthusiastic','bold','brave','daring',\n",
    "            'optimistic','impulsive','free','sure','certain','rebellious','unique','dynamic','tenacious','hardy','secure',\n",
    "            'confident','challenged', 'love'];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Read csv\n",
    "path = 'Resources/Amazon_rev.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "amazon_foods_df = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Drop first column because it creates junk info\n",
    "amazon_foods_df = amazon_foods_df.drop(columns=[\"Unnamed: 0\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy of dataframe\n",
    "amazon_foods_modified_df = amazon_foods_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a regular expression to look for all the symbols\n",
    "regex = \"[.\\\"\\',!@#$%^&*()\\_\\-+=?:;|/!]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tex replacement for all rules in the regex\n",
    "text_replace = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create first column with text in lower case and no special characters\n",
    "amazon_foods_modified_df['Lowercase Text'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data frame to run demo version\n",
    "amazon_foods_modified_df = amazon_foods_df.iloc[:50000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.6 s, sys: 181 ms, total: 11.8 s\n",
      "Wall time: 11.8 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Gugunner-Oryx-Pro/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Populate new column column \n",
    "amazon_foods_modified_df['Lowercase Text'] = amazon_foods_df.apply(\n",
    "    lambda row: (\n",
    "            re.sub(\n",
    "                regex,\n",
    "                text_replace,\n",
    "                row[9].lower()\n",
    "            )\n",
    "    ),\n",
    "    axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Gugunner-Oryx-Pro/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#Create second column and clear br html tags\n",
    "amazon_foods_modified_df['Lowercase Text Clean'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to extract with beautifull soup br and just return text property\n",
    "def extract_br_tags(soup):\n",
    "    for e in soup.findAll('br'):\n",
    "        e.extract()    \n",
    "    if soup.find('p'):\n",
    "        return soup.find('p').text\n",
    "    elif soup.find('span'):\n",
    "        return soup.find('span').text\n",
    "    elif soup.find('a'):\n",
    "        return soup.find('a').text\n",
    "    return soup.find('body').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to count positive and negative words based on pleasant and unpleasant lists\n",
    "def add_positive_negative(text, is_positive):\n",
    "    text_list = text.split()\n",
    "    count = 0\n",
    "    for word in text_list:\n",
    "        if is_positive:\n",
    "            for pleasant_word in pleasant:\n",
    "                if word == pleasant_word:\n",
    "                    count+=1\n",
    "        else:\n",
    "            for unpleasant_word in unpleasant:\n",
    "                if word == unpleasant_word:\n",
    "                    count+=1\n",
    "    return count\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13.3 s, sys: 304 ms, total: 13.6 s\n",
      "Wall time: 13.7 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Gugunner-Oryx-Pro/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "amazon_foods_modified_df['Lowercase Text Clean'] = amazon_foods_modified_df.apply(\n",
    "    lambda row: (\n",
    "        extract_br_tags(bs(row[10],'lxml'))\n",
    "    ),\n",
    "    axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Gugunner-Oryx-Pro/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Create column for positive count\n",
    "amazon_foods_modified_df['Positive Count'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.3 s, sys: 28.6 ms, total: 10.3 s\n",
      "Wall time: 10.3 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Gugunner-Oryx-Pro/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "amazon_foods_modified_df['Positive Count'] = amazon_foods_modified_df.apply(\n",
    "    lambda row: (\n",
    "        add_positive_negative(row[11], True)\n",
    "    ),\n",
    "    axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Gugunner-Oryx-Pro/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Create column for negative count\n",
    "amazon_foods_modified_df['Negative Count'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13.3 s, sys: 34.7 ms, total: 13.3 s\n",
      "Wall time: 13.3 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Gugunner-Oryx-Pro/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "amazon_foods_modified_df['Negative Count'] = amazon_foods_modified_df.apply(\n",
    "    lambda row: (\n",
    "        add_positive_negative(row[11], False)\n",
    "    ),\n",
    "    axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "      <th>Lowercase Text</th>\n",
       "      <th>Lowercase Text Clean</th>\n",
       "      <th>Positive Count</th>\n",
       "      <th>Negative Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "      <td>i have bought several of the vitality canned d...</td>\n",
       "      <td>i have bought several of the vitality canned d...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "      <td>product arrived labeled as jumbo salted peanut...</td>\n",
       "      <td>product arrived labeled as jumbo salted peanut...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "      <td>this is a confection that has been around a fe...</td>\n",
       "      <td>this is a confection that has been around a fe...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>A395BORC6FGVXV</td>\n",
       "      <td>Karl</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>negative</td>\n",
       "      <td>1307923200</td>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "      <td>if you are looking for the secret ingredient i...</td>\n",
       "      <td>if you are looking for the secret ingredient i...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A1UQRSCLF8GW1T</td>\n",
       "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>positive</td>\n",
       "      <td>1350777600</td>\n",
       "      <td>Great taffy</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "      <td>great taffy at a great price  there was a wide...</td>\n",
       "      <td>great taffy at a great price  there was a wide...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49995</td>\n",
       "      <td>54290</td>\n",
       "      <td>B004V3INB0</td>\n",
       "      <td>A11F42B0Q3ET89</td>\n",
       "      <td>baxter</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>positive</td>\n",
       "      <td>1330905600</td>\n",
       "      <td>jamaica me crazy k-cups/flavor</td>\n",
       "      <td>i had taste tested this when a friend gave a c...</td>\n",
       "      <td>i had taste tested this when a friend gave a c...</td>\n",
       "      <td>i had taste tested this when a friend gave a c...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49996</td>\n",
       "      <td>54291</td>\n",
       "      <td>B004V3INB0</td>\n",
       "      <td>AFHBO1FR7COBF</td>\n",
       "      <td>Atypical Soccer Mom \"cook, teacher, personal ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "      <td>1327708800</td>\n",
       "      <td>Not Comparable to Green Mountain Coffee Roaste...</td>\n",
       "      <td>I bought this coffee in the hopes that it woul...</td>\n",
       "      <td>i bought this coffee in the hopes that it woul...</td>\n",
       "      <td>i bought this coffee in the hopes that it woul...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49997</td>\n",
       "      <td>54292</td>\n",
       "      <td>B004V3INB0</td>\n",
       "      <td>A18UUSTSQJYK8O</td>\n",
       "      <td>Tamra L. Bowman \"tamrabear\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>positive</td>\n",
       "      <td>1319673600</td>\n",
       "      <td>My favorite..... I can't live without it !</td>\n",
       "      <td>I'm going to go broke drinking these.  I disco...</td>\n",
       "      <td>im going to go broke drinking these  i discove...</td>\n",
       "      <td>im going to go broke drinking these  i discove...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49998</td>\n",
       "      <td>54293</td>\n",
       "      <td>B004V3INB0</td>\n",
       "      <td>A3E2QMBUB7VQOI</td>\n",
       "      <td>Nola Belle</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>positive</td>\n",
       "      <td>1311465600</td>\n",
       "      <td>Pretty Good</td>\n",
       "      <td>Reviews for coffee can be hard, because everyo...</td>\n",
       "      <td>reviews for coffee can be hard because everyon...</td>\n",
       "      <td>reviews for coffee can be hard because everyon...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49999</td>\n",
       "      <td>54294</td>\n",
       "      <td>B004V3INB0</td>\n",
       "      <td>A3AZI828WJN1CD</td>\n",
       "      <td>Becky (beckygardens)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "      <td>1311120000</td>\n",
       "      <td>Nasty</td>\n",
       "      <td>This tasted like the cheapest fake coconut tas...</td>\n",
       "      <td>this tasted like the cheapest fake coconut tas...</td>\n",
       "      <td>this tasted like the cheapest fake coconut tas...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Id   ProductId          UserId  \\\n",
       "0          1  B001E4KFG0  A3SGXH7AUHU8GW   \n",
       "1          2  B00813GRG4  A1D87F6ZCVE5NK   \n",
       "2          3  B000LQOCH0   ABXLMWJIXXAIN   \n",
       "3          4  B000UA0QIQ  A395BORC6FGVXV   \n",
       "4          5  B006K2ZZ7K  A1UQRSCLF8GW1T   \n",
       "...      ...         ...             ...   \n",
       "49995  54290  B004V3INB0  A11F42B0Q3ET89   \n",
       "49996  54291  B004V3INB0   AFHBO1FR7COBF   \n",
       "49997  54292  B004V3INB0  A18UUSTSQJYK8O   \n",
       "49998  54293  B004V3INB0  A3E2QMBUB7VQOI   \n",
       "49999  54294  B004V3INB0  A3AZI828WJN1CD   \n",
       "\n",
       "                                            ProfileName  HelpfulnessNumerator  \\\n",
       "0                                            delmartian                     1   \n",
       "1                                                dll pa                     0   \n",
       "2                       Natalia Corres \"Natalia Corres\"                     1   \n",
       "3                                                  Karl                     3   \n",
       "4                         Michael D. Bigham \"M. Wassir\"                     0   \n",
       "...                                                 ...                   ...   \n",
       "49995                                            baxter                     0   \n",
       "49996  Atypical Soccer Mom \"cook, teacher, personal ...                     0   \n",
       "49997                       Tamra L. Bowman \"tamrabear\"                     0   \n",
       "49998                                        Nola Belle                     0   \n",
       "49999                              Becky (beckygardens)                     0   \n",
       "\n",
       "       HelpfulnessDenominator     Score        Time  \\\n",
       "0                           1  positive  1303862400   \n",
       "1                           0  negative  1346976000   \n",
       "2                           1  positive  1219017600   \n",
       "3                           3  negative  1307923200   \n",
       "4                           0  positive  1350777600   \n",
       "...                       ...       ...         ...   \n",
       "49995                       0  positive  1330905600   \n",
       "49996                       0  negative  1327708800   \n",
       "49997                       0  positive  1319673600   \n",
       "49998                       0  positive  1311465600   \n",
       "49999                       0  negative  1311120000   \n",
       "\n",
       "                                                 Summary  \\\n",
       "0                                  Good Quality Dog Food   \n",
       "1                                      Not as Advertised   \n",
       "2                                  \"Delight\" says it all   \n",
       "3                                         Cough Medicine   \n",
       "4                                            Great taffy   \n",
       "...                                                  ...   \n",
       "49995                     jamaica me crazy k-cups/flavor   \n",
       "49996  Not Comparable to Green Mountain Coffee Roaste...   \n",
       "49997         My favorite..... I can't live without it !   \n",
       "49998                                        Pretty Good   \n",
       "49999                                              Nasty   \n",
       "\n",
       "                                                    Text  \\\n",
       "0      I have bought several of the Vitality canned d...   \n",
       "1      Product arrived labeled as Jumbo Salted Peanut...   \n",
       "2      This is a confection that has been around a fe...   \n",
       "3      If you are looking for the secret ingredient i...   \n",
       "4      Great taffy at a great price.  There was a wid...   \n",
       "...                                                  ...   \n",
       "49995  i had taste tested this when a friend gave a c...   \n",
       "49996  I bought this coffee in the hopes that it woul...   \n",
       "49997  I'm going to go broke drinking these.  I disco...   \n",
       "49998  Reviews for coffee can be hard, because everyo...   \n",
       "49999  This tasted like the cheapest fake coconut tas...   \n",
       "\n",
       "                                          Lowercase Text  \\\n",
       "0      i have bought several of the vitality canned d...   \n",
       "1      product arrived labeled as jumbo salted peanut...   \n",
       "2      this is a confection that has been around a fe...   \n",
       "3      if you are looking for the secret ingredient i...   \n",
       "4      great taffy at a great price  there was a wide...   \n",
       "...                                                  ...   \n",
       "49995  i had taste tested this when a friend gave a c...   \n",
       "49996  i bought this coffee in the hopes that it woul...   \n",
       "49997  im going to go broke drinking these  i discove...   \n",
       "49998  reviews for coffee can be hard because everyon...   \n",
       "49999  this tasted like the cheapest fake coconut tas...   \n",
       "\n",
       "                                    Lowercase Text Clean  Positive Count  \\\n",
       "0      i have bought several of the vitality canned d...               0   \n",
       "1      product arrived labeled as jumbo salted peanut...               1   \n",
       "2      this is a confection that has been around a fe...               0   \n",
       "3      if you are looking for the secret ingredient i...               0   \n",
       "4      great taffy at a great price  there was a wide...               2   \n",
       "...                                                  ...             ...   \n",
       "49995  i had taste tested this when a friend gave a c...               1   \n",
       "49996  i bought this coffee in the hopes that it woul...               0   \n",
       "49997  im going to go broke drinking these  i discove...               0   \n",
       "49998  reviews for coffee can be hard because everyon...               0   \n",
       "49999  this tasted like the cheapest fake coconut tas...               0   \n",
       "\n",
       "       Negative Count  \n",
       "0                   0  \n",
       "1                   0  \n",
       "2                   0  \n",
       "3                   0  \n",
       "4                   0  \n",
       "...               ...  \n",
       "49995               1  \n",
       "49996               1  \n",
       "49997               0  \n",
       "49998               0  \n",
       "49999               0  \n",
       "\n",
       "[50000 rows x 14 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazon_foods_modified_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns not needed for modified csv\n",
    "amazon_foods_modified_df = amazon_foods_modified_df.drop(columns=['Lowercase Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon_foods_modified_df.to_csv('Amazon_rev_modified.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (Bootcamp_Data_Analytics)",
   "language": "python",
   "name": "pycharm-47a15ae5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
