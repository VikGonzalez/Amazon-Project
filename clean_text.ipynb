{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of unpleasant words to check\n",
    "unpleasant = ['lousy','disappointed','discouraged','ashamed','powerless','diminished','guilty','dissatisfied',\n",
    "        'miserable','detestable','repugnant','despicable','disgusting','abominable','terrible','in despair',\n",
    "        'sulky','bad','upset','doubtful','uncertain','indecisive','perplexed','embarassed','hesitant',\n",
    "        'shy','stupefied','disillusioned','unbelieving','skeptical','distrustful','misgiving','lost',\n",
    "        'unsure','uneasy','pessimistic','tense''incapable','alone','paralyzed','fatigued','useless',\n",
    "        'inferior','vulnerable','empty','forced','hesitant','despair','frustrated','distressed','woeful',\n",
    "        'pathetic','tragic','in a stew','dominated','irritated','enraged','hostile','insulting',\n",
    "        'annoyed','upset','hateful','offensive','bitter','aggresive','resentful','inflamed','provoked',\n",
    "        'incensed','infuriated','cross','worked up','boiling','fuming','fearful','terrified','suspicious',\n",
    "        'anxious','alarmed','panic','nervous','scared','worried','frightened','timid','shaky','restless',\n",
    "        'doubtful','threatened','cowardly','quaking','wary','crushed','tormented','deprived','pained',\n",
    "        'tortured','dejected','rejected','injured','offended','afflicted','aching','victimized',\n",
    "        'heartbroken','agonized','appalled','humiliated','wronged','alienated','tearful','sorrowful',\n",
    "        'pained','grief','anguish','desolate','desperate','pessimistic','unhappy','lonely','grieved',\n",
    "        'mournful','dismayed','insensitive','dull','nonchalant','neutral','reserved','weary','bored',\n",
    "        'preoccupied','cold','disinterested','lifeless', 'never'];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of pleasant words to check\n",
    "pleasant = ['understanding','confident','reliable','easy','amazed','free','sympathetic','interested','satisfied',\n",
    "            'receptive','accepting','kind', 'great','joyous','lucky','fortunate','delighted','overjoyed','gleeful','thankful','important',\n",
    "            'festive','ecstatic','glad','cheerful','elated','jubilant', 'playful','courageous','energetic','liberated','optimistic',\n",
    "            'impulsive','free','animated','spirited','thrilled','wonderful','calm','peaceful','at ease','comfortable','pleased','encouraged',\n",
    "            'clever','surprised','content','quiet','certain','relaxed','serene','reassured', 'loving','considerate','affectionate', 'sensitive',\n",
    "            'tender','devoted','attracted','passionate','admiration','warm','touched','close','comforted','loved','concerned','affected','fascinated',\n",
    "            'intrigued','absorbed','inquisitive','engrossed','curious','drawn toward','eager','keen','earnest','intent','inspired','determined','excited',\n",
    "            'enthusiastic','bold','brave','daring',\n",
    "            'optimistic','impulsive','free','sure','certain','rebellious','unique','dynamic','tenacious','hardy','secure',\n",
    "            'confident','challenged', 'love'];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Read csv\n",
    "path = 'Resources/Amazon_rev.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "amazon_foods_df = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Drop first column because it creates junk info\n",
    "amazon_foods_df = amazon_foods_df.drop(columns=[\"Unnamed: 0\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy of dataframe\n",
    "amazon_foods_modified_df = amazon_foods_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a regular expression to look for all the symbols\n",
    "regex = \"[.\\\"\\',!@#$%^&*()\\_\\-+=?:;|/!]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tex replacement for all rules in the regex\n",
    "text_replace = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create first column with text in lower case and no special characters\n",
    "amazon_foods_modified_df['Lowercase Text'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data frame to run demo version\n",
    "amazon_foods_modified_df = amazon_foods_df.iloc[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 17.5 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\victo\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Populate new column column \n",
    "amazon_foods_modified_df['Lowercase Text'] = amazon_foods_df.apply(\n",
    "    lambda row: (\n",
    "            re.sub(\n",
    "                regex,\n",
    "                text_replace,\n",
    "                row[9].lower()\n",
    "            )\n",
    "    ),\n",
    "    axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\victo\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#Create second column and clear br html tags\n",
    "amazon_foods_modified_df['Lowercase Text Clean'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to extract with beautifull soup br and just return text property\n",
    "def extract_br_tags(soup):\n",
    "    for e in soup.findAll('br'):\n",
    "        e.extract()    \n",
    "    if soup.find('p'):\n",
    "        return soup.find('p').text\n",
    "    elif soup.find('span'):\n",
    "        return soup.find('span').text\n",
    "    elif soup.find('a'):\n",
    "        return soup.find('a').text\n",
    "    return soup.find('body').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to count positive and negative words based on pleasant and unpleasant lists\n",
    "def add_positive_negative(text, is_positive):\n",
    "    text_list = text.split()\n",
    "    count = 0\n",
    "    for word in text_list:\n",
    "        if is_positive:\n",
    "            for pleasant_word in pleasant:\n",
    "                if word == pleasant_word:\n",
    "                    count+=1\n",
    "        else:\n",
    "            for unpleasant_word in unpleasant:\n",
    "                if word == unpleasant_word:\n",
    "                    count+=1\n",
    "    return count\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 94.9 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\victo\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "amazon_foods_modified_df['Lowercase Text Clean'] = amazon_foods_modified_df.apply(\n",
    "    lambda row: (\n",
    "        extract_br_tags(bs(row[10],'lxml'))\n",
    "    ),\n",
    "    axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\victo\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Create column for positive count\n",
    "amazon_foods_modified_df['Positive Count'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 36.6 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\victo\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "amazon_foods_modified_df['Positive Count'] = amazon_foods_modified_df.apply(\n",
    "    lambda row: (\n",
    "        add_positive_negative(row[11], True)\n",
    "    ),\n",
    "    axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\victo\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Create column for negative count\n",
    "amazon_foods_modified_df['Negative Count'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 46 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\victo\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "amazon_foods_modified_df['Negative Count'] = amazon_foods_modified_df.apply(\n",
    "    lambda row: (\n",
    "        add_positive_negative(row[11], False)\n",
    "    ),\n",
    "    axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "      <th>Lowercase Text</th>\n",
       "      <th>Lowercase Text Clean</th>\n",
       "      <th>Positive Count</th>\n",
       "      <th>Negative Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "      <td>i have bought several of the vitality canned d...</td>\n",
       "      <td>i have bought several of the vitality canned d...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "      <td>product arrived labeled as jumbo salted peanut...</td>\n",
       "      <td>product arrived labeled as jumbo salted peanut...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "      <td>this is a confection that has been around a fe...</td>\n",
       "      <td>this is a confection that has been around a fe...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>A395BORC6FGVXV</td>\n",
       "      <td>Karl</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>negative</td>\n",
       "      <td>1307923200</td>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "      <td>if you are looking for the secret ingredient i...</td>\n",
       "      <td>if you are looking for the secret ingredient i...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A1UQRSCLF8GW1T</td>\n",
       "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>positive</td>\n",
       "      <td>1350777600</td>\n",
       "      <td>Great taffy</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "      <td>great taffy at a great price  there was a wide...</td>\n",
       "      <td>great taffy at a great price  there was a wide...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>105</td>\n",
       "      <td>B004K2IHUO</td>\n",
       "      <td>AL3E5V6MXO9B0</td>\n",
       "      <td>pionex1796</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>positive</td>\n",
       "      <td>1326412800</td>\n",
       "      <td>Loved these Tartlets</td>\n",
       "      <td>What a nice alternative to an apple pie. Love ...</td>\n",
       "      <td>what a nice alternative to an apple pie love t...</td>\n",
       "      <td>what a nice alternative to an apple pie love t...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>106</td>\n",
       "      <td>B004K2IHUO</td>\n",
       "      <td>A2O9G2521O626G</td>\n",
       "      <td>Rachel Westendorf</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>positive</td>\n",
       "      <td>1308700800</td>\n",
       "      <td>The best</td>\n",
       "      <td>I like Creme Brulee. I loved that these were s...</td>\n",
       "      <td>i like creme brulee i loved that these were so...</td>\n",
       "      <td>i like creme brulee i loved that these were so...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>108</td>\n",
       "      <td>B001REEG6C</td>\n",
       "      <td>A30835UIR6F8KB</td>\n",
       "      <td>Adam E. Smith</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>positive</td>\n",
       "      <td>1295308800</td>\n",
       "      <td>Wasting Vinegar on a Cucumber is a Shame!</td>\n",
       "      <td>I first bought pickled asparagus at an Amish m...</td>\n",
       "      <td>i first bought pickled asparagus at an amish m...</td>\n",
       "      <td>i first bought pickled asparagus at an amish m...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>109</td>\n",
       "      <td>B001REEG6C</td>\n",
       "      <td>A10EHUTGNC4BGP</td>\n",
       "      <td>M. Foell</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "      <td>1243728000</td>\n",
       "      <td>Asparagus Bliss</td>\n",
       "      <td>I love asparagus.  Up until very recently, I h...</td>\n",
       "      <td>i love asparagus  up until very recently i had...</td>\n",
       "      <td>i love asparagus  up until very recently i had...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>110</td>\n",
       "      <td>B001REEG6C</td>\n",
       "      <td>AY12DBB0U420B</td>\n",
       "      <td>Gary Peterson</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>positive</td>\n",
       "      <td>1316390400</td>\n",
       "      <td>My Idea of a Good Diet Food.</td>\n",
       "      <td>I'm presently on a diet and I was at my Fresh ...</td>\n",
       "      <td>im presently on a diet and i was at my fresh a...</td>\n",
       "      <td>im presently on a diet and i was at my fresh a...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Id   ProductId          UserId                      ProfileName  \\\n",
       "0     1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
       "1     2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
       "2     3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
       "3     4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
       "4     5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
       "..  ...         ...             ...                              ...   \n",
       "95  105  B004K2IHUO   AL3E5V6MXO9B0                       pionex1796   \n",
       "96  106  B004K2IHUO  A2O9G2521O626G                Rachel Westendorf   \n",
       "97  108  B001REEG6C  A30835UIR6F8KB                    Adam E. Smith   \n",
       "98  109  B001REEG6C  A10EHUTGNC4BGP                         M. Foell   \n",
       "99  110  B001REEG6C   AY12DBB0U420B                    Gary Peterson   \n",
       "\n",
       "    HelpfulnessNumerator  HelpfulnessDenominator     Score        Time  \\\n",
       "0                      1                       1  positive  1303862400   \n",
       "1                      0                       0  negative  1346976000   \n",
       "2                      1                       1  positive  1219017600   \n",
       "3                      3                       3  negative  1307923200   \n",
       "4                      0                       0  positive  1350777600   \n",
       "..                   ...                     ...       ...         ...   \n",
       "95                     0                       0  positive  1326412800   \n",
       "96                     0                       0  positive  1308700800   \n",
       "97                     2                       2  positive  1295308800   \n",
       "98                     1                       1  positive  1243728000   \n",
       "99                     0                       0  positive  1316390400   \n",
       "\n",
       "                                      Summary  \\\n",
       "0                       Good Quality Dog Food   \n",
       "1                           Not as Advertised   \n",
       "2                       \"Delight\" says it all   \n",
       "3                              Cough Medicine   \n",
       "4                                 Great taffy   \n",
       "..                                        ...   \n",
       "95                       Loved these Tartlets   \n",
       "96                                   The best   \n",
       "97  Wasting Vinegar on a Cucumber is a Shame!   \n",
       "98                            Asparagus Bliss   \n",
       "99               My Idea of a Good Diet Food.   \n",
       "\n",
       "                                                 Text  \\\n",
       "0   I have bought several of the Vitality canned d...   \n",
       "1   Product arrived labeled as Jumbo Salted Peanut...   \n",
       "2   This is a confection that has been around a fe...   \n",
       "3   If you are looking for the secret ingredient i...   \n",
       "4   Great taffy at a great price.  There was a wid...   \n",
       "..                                                ...   \n",
       "95  What a nice alternative to an apple pie. Love ...   \n",
       "96  I like Creme Brulee. I loved that these were s...   \n",
       "97  I first bought pickled asparagus at an Amish m...   \n",
       "98  I love asparagus.  Up until very recently, I h...   \n",
       "99  I'm presently on a diet and I was at my Fresh ...   \n",
       "\n",
       "                                       Lowercase Text  \\\n",
       "0   i have bought several of the vitality canned d...   \n",
       "1   product arrived labeled as jumbo salted peanut...   \n",
       "2   this is a confection that has been around a fe...   \n",
       "3   if you are looking for the secret ingredient i...   \n",
       "4   great taffy at a great price  there was a wide...   \n",
       "..                                                ...   \n",
       "95  what a nice alternative to an apple pie love t...   \n",
       "96  i like creme brulee i loved that these were so...   \n",
       "97  i first bought pickled asparagus at an amish m...   \n",
       "98  i love asparagus  up until very recently i had...   \n",
       "99  im presently on a diet and i was at my fresh a...   \n",
       "\n",
       "                                 Lowercase Text Clean  Positive Count  \\\n",
       "0   i have bought several of the vitality canned d...               0   \n",
       "1   product arrived labeled as jumbo salted peanut...               1   \n",
       "2   this is a confection that has been around a fe...               0   \n",
       "3   if you are looking for the secret ingredient i...               0   \n",
       "4   great taffy at a great price  there was a wide...               2   \n",
       "..                                                ...             ...   \n",
       "95  what a nice alternative to an apple pie love t...               3   \n",
       "96  i like creme brulee i loved that these were so...               3   \n",
       "97  i first bought pickled asparagus at an amish m...               1   \n",
       "98  i love asparagus  up until very recently i had...               3   \n",
       "99  im presently on a diet and i was at my fresh a...               1   \n",
       "\n",
       "    Negative Count  \n",
       "0                0  \n",
       "1                0  \n",
       "2                0  \n",
       "3                0  \n",
       "4                0  \n",
       "..             ...  \n",
       "95               0  \n",
       "96               0  \n",
       "97               0  \n",
       "98               1  \n",
       "99               0  \n",
       "\n",
       "[100 rows x 14 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazon_foods_modified_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns not needed for modified csv\n",
    "amazon_foods_modified_df = amazon_foods_modified_df.drop(columns=['Lowercase Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon_foods_modified_df.to_csv('Amazon_rev_modified.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
